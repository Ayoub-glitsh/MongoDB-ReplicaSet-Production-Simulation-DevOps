
ğŸ“˜ Documentation â€“ MongoDB Replica Set Setup Simulation (Production-Oriented)
=============================================================================
<div style="display: flex; flex-wrap: wrap; justify-content: center; gap: 10px;">

<!-- Ligne 1 -->
<img src="img/replicaSet_01.png" alt="Replica Set 1" width="200" height="150" />
<img src="img/replicaSet_02.png" alt="Mongo Shell 1" width="200" height="150" />
<img src="img/replicaSet_03.png" alt="Election 1" width="200" height="150" />
<img src="img/replicaSet_04.png" alt="Replication 1" width="200" height="150" />

<!-- Ligne 2 -->
<img src="img/replicaSet_05.png" alt="Error 1" width="200" height="150" />
<img src="img/replicaSet_06.png" alt="Replica Set 2" width="200" height="150" />
<img src="img/replicaSet_07.png" alt="Mongo Shell 2" width="200" height="150" />
<img src="img/replicatSet_08.png" alt="Election 2" width="200" height="150" />

<!-- Ligne 3 -->
<img src="img/replicaSet_09.png" alt="Replication 2" width="200" height="150" />
<img src="img/replicaSet_10.png" alt="Error 2" width="200" height="150" />
<img src="img/replicaSet_11.png" alt="Replica Set 3" width="200" height="150" />
<img src="img/replicaSet_12.png" alt="Mongo Shell 3" width="200" height="150" />

</div>








Replica Set Name: `myReplicaSet`
--------------------------------

* * *

1ï¸âƒ£ Simulation Objective
------------------------

The objective of this simulation is to **set up and operate a MongoDB Replica Set cluster** in a production-like environment in order to:

*   Understand the roles of **Primary** and **Secondary** nodes
*   Observe **automatic elections**  
*   Test **data replication**
*   Verify **write restrictions**
*   Diagnose **real-world production errors**
    

* * *


## 2ï¸âƒ£ Environment Used

| Element             | Value               |
| ------------------- | ----------------- |
| OS                  | Windows           |
| MongoDB             | 8.2.1             |
| mongosh             | 2.5.8             |
| Deployment Type     | Local (simulation)|
| Mode                | Replica Set       |




* * *

3ï¸âƒ£ Connection to the Initial Primary Node
------------------------------------------

Connection to MongoDB server on port **2717**:

    mongosh --port 2717
    

Result:

*   Successful connection
*   Node is **Primary**
*   Active Replica Set: `myReplicaSet`
    

* * *

4ï¸âƒ£ Initial Replica Set Status Check
------------------------------------

Executed command:

    rs.status()
    
### ğŸ” Observation

*   `votingMembersCount: 1`
*   `stateStr: PRIMARY`
*   Only one active node
*   No fault tolerance yet
    
ğŸ‘‰ The Replica Set is operational but **not redundant**

* * *

5ï¸âƒ£ Adding Secondary Nodes
--------------------------

### â• Add first Secondary

    rs.add("localhost:2727")
    

### â• Add second Secondary

    rs.add("localhost:2737")
    

* * *

6ï¸âƒ£ Cluster Status After Adding Nodes
-------------------------------------

    rs.status()
    

### ğŸ” Result

| Element            | Value          |
| ------------------ | -------------- |
| Total nodes        | 3              |
| Primary            | localhost:2717 |
| Secondary          | localhost:2727 |
| Secondary          | localhost:2737 |
| votingMembersCount | 3              |
| writeMajorityCount | 2              |


âœ… The cluster is now **highly available**

* * *

7ï¸âƒ£ Shell Behavior Test (`rs.status` vs `rs.status()`)
------------------------------------------------------

Incorrect command:

    rs.status
    

Result:

*   Returns a **function reference**
*   No execution
    

Correct command:

    rs.status()
    

ğŸ‘‰ This highlights the difference between:

*   **Function reference**
*   **Function execution**
    

* * *

8ï¸âƒ£ Restart and Temporary Connection Loss
-----------------------------------------

Reconnection attempt:

    mongosh --port 2717
    

Result:

    MongoNetworkError: connect ECONNREFUSED
    

### ğŸ” Interpretation

*   The node on port 2717 was **down**
*   The Replica Set triggered an **automatic election**
    

* * *

9ï¸âƒ£ New Election Observation
----------------------------

Connection to another node:

    mongosh --port 2727
    rs.status()
    

### ğŸ” Result

*   `localhost:2727` becomes **PRIMARY**
*   `localhost:2717` becomes **SECONDARY**
*   `term` incremented (moved to `term: 2`)
    

âœ… **Fault tolerance confirmed**

* * *

ğŸ”Ÿ Write Attempt on a Secondary (Expected Failure)
--------------------------------------------------

Connection to a Secondary:

    mongosh --port 2717
    

Insert attempt:

    db.users.insert({ "name": "my name is Ayoub" })
    

Result:

    MongoBulkWriteError[NotWritablePrimary]: not primary
    

### ğŸ§  Explanation

*   **Write operations are forbidden** on Secondary nodes
*   Only the **Primary** accepts writes
    

âœ… Normal production behavior

* * *

1ï¸âƒ£1ï¸âƒ£ Data Insertion on the Primary
------------------------------------

Connection to the Primary:

    mongosh --port 2727
    

Successful insert:

    db.random.insertOne({ "name": "My name is Ayoub" })
    

Result:

    acknowledged: true
    

* * *

1ï¸âƒ£2ï¸âƒ£ Replication Verification
-------------------------------

Connection to a Secondary:

    mongosh --port 2717
    

    use Ayoub
    show collections
    

Result:

*   The `random` collection is present
    
*   Data has been **automatically replicated**
    

âœ… Replication is functional

* * *

1ï¸âƒ£3ï¸âƒ£ Encountered Issue: BSON / UTF-8 Error
--------------------------------------------

Observed error:

    BSONError: Invalid UTF-8 string in BSON document
    

### ğŸ” Identified Cause

*   MongoDB version **8.2**
*   Feature Compatibility Version:
    
```bash
    db.system.version.find()
    { version: "8.2" }
```   

ğŸ‘‰ Version is too recent â†’ instability with some commands (`rs.status()`)

* * *

1ï¸âƒ£4ï¸âƒ£ Security Warnings (Non-Production Mode)
----------------------------------------------

At startup:

    Access control is not enabled
    Server is bound to localhost
    

### ğŸ” Interpretation

*   No authentication enabled
*   Access restricted to `localhost`
*   Acceptable for **simulation**
*   âŒ Not recommended for production
    

* * *

1ï¸âƒ£5ï¸âƒ£ Results and Skills Acquired
----------------------------------

### âœ… Validated Skills

*   Replica Set setup
*   Dynamic node addition
*   `rs.status()` analysis
*   Election mechanism understanding
*   Handling `NotWritablePrimary` errors
*   Automatic data replication
*   BSON / FCV issue diagnostics
    

* * *

1ï¸âƒ£6ï¸âƒ£ Conclusion
-----------------

This simulation successfully reproduced a **production-like MongoDB environment**, demonstrating:

*   Real Replica Set behavior
*   High availability
*   Write limitations
*   Automatic elections
*   Version-related errors
    
It provides a **solid foundation** for backend, DevOps, and cloud projects.

* * *

ğŸ“Œ Future Improvements
----------------------

*   Enable authentication (`--auth`)
*   Add TLS/SSL
*   Downgrade FCV to 7.0
*   Dockerize the cluster
*   Add monitoring (Prometheus / MongoDB Compass)
    




***


# MongoDB Replica Set Production Architecture

  

## 1ï¸âƒ£ Production Architecture Overview

  

```mermaid
graph TB
Â  Â  subgraph "Application Layer"
Â  Â  Â  Â  App[Client Application]
Â  Â  end
Â  Â  subgraph "MongoDB Replica Set: myReplicaSet"
Â  Â  Â  Â  P[Primary Node
localhost:2717]
Â  Â  Â  Â  S1[Secondary Node 1
localhost:2727]
Â  Â  Â  Â  S2[Secondary Node 2
localhost:2737]
Â  Â  end
Â  Â  subgraph "Data Storage"
Â  Â  Â  Â  DP[(Primary Data
Oplog)]
Â  Â  Â  Â  DS1[(Secondary Data 1
Replicated)]
Â  Â  Â  Â  DS2[(Secondary Data 2
Replicated)]
Â  Â  end
Â  Â  App -- "Write Operations
Read/Write" --> P
Â  Â  App -- "Read Operations
(Optional)" --> S1
Â  Â  App -- "Read Operations
(Optional)" --> S2
Â  Â  P -- "Heartbeat & Replication" --> S1
Â  Â  P -- "Heartbeat & Replication" --> S2
Â  Â  S1 -- "Heartbeat" --> S2
Â  Â  P --- DP
Â  Â  S1 --- DS1
Â  Â  S2 --- DS2
Â  Â  classDef primary fill:#e1f5fe,stroke:#0288d1,stroke-width:2px
Â  Â  classDef secondary fill:#f3e5f5,stroke:#7b1fa2
Â  Â  classDef storage fill:#e8f5e8,stroke:#2e7d32
Â  Â  class P,DP primary
Â  Â  class S1,DS1,S2,DS2 secondary
Â  Â  class DP,DS1,DS2 storage
```

  

### ğŸ› ï¸ Technical Explanation

This production architecture illustrates a **MongoDB Replica Set** with **three nodes** deployed on different ports on `localhost` (simulating separate servers).
---
- **ğŸŸ¢ Primary Node** (`localhost:2717`):  
  - Handles **all write operations**  
  - Coordinates **replication** to both Secondary nodes  
---
- **ğŸ”µ Secondary Nodes** (`localhost:2727` & `localhost:2737`):  
  - Serve **read operations** to distribute query load  
  - Receive data replicated from the Primary  
---
- **ğŸ’“ Heartbeats & Cluster Health**:  
  - All nodes maintain **continuous communication**  
  - Enable **automatic failover** if the Primary goes down  
---
> âœ… This setup simulates a **production-ready MongoDB cluster**, providing **high availability**, **fault tolerance**, and **read scalability**.



  

## 2ï¸âƒ£ Write Operation Flow

  

```mermaid

sequenceDiagram

Â  Â  participant C as Client/Application

Â  Â  participant P as Primary (2717)

Â  Â  participant S1 as Secondary 1 (2727)

Â  Â  participant S2 as Secondary 2 (2737)

Â  Â  participant O as Oplog

Â  Â  Note over P,S2: Initial State: All nodes synchronized

Â  Â  C->>P: 1. Insert/Update/Delete Request

Â  Â  P->>O: 2. Write to Oplog (capped collection)

Â  Â  P->>C: 3. Acknowledge Write (immediately)

Â  Â  par Replication to Secondaries

Â  Â  Â  Â  P->>S1: 4. Oplog Entry Replication

Â  Â  Â  Â  S1->>S1: 5. Apply Oplog Entry

Â  Â  Â  Â  S1->>P: 6. Replication Acknowledgement

Â  Â  Â  Â  and

Â  Â  Â  Â  P->>S2: 4. Oplog Entry Replication

Â  Â  Â  Â  S2->>S2: 5. Apply Oplog Entry

Â  Â  Â  Â  S2->>P: 6. Replication Acknowledgement

Â  Â  end

Â  Â  Note over P,S2: Eventual Consistency: Secondaries catch up

```

  
### ğŸ“ Technical Explanation â€“ Write Flow

Write operations in a **MongoDB Replica Set** follow a **specific flow** to ensure **data durability** and **performance**:
---
1. **ğŸ§‘â€ğŸ’» Client â†’ Primary**  
   - The client sends **write operations exclusively** to the **Primary node**  
---
2. **ğŸ—‚ï¸ Primary Oplog Logging**  
   - Primary writes the operation to its **Oplog** (operations log)  
   - The Oplog is a **capped collection** that tracks all data changes  
---
3. **âœ… Primary Acknowledgment**  
   - Primary immediately **acknowledges the write** to the client  
   - Default **write concern** ensures confirmation without waiting for secondaries  
---
4. **ğŸ”„ Replication to Secondaries**  
   - Primary **asynchronously replicates** Oplog entries to all Secondary nodes  
---
5. **ğŸ“¥ Secondary Application**  
   - Each Secondary **applies operations in the same order** as the Primary  
---
6. **ğŸ“¤ Replication Acknowledgment**  
   - Secondaries **acknowledge replication completion** back to the Primary  

> âš¡ This flow ensures **durable writes** while maintaining **high performance** through **asynchronous replication**.


  

## 3ï¸âƒ£ Automatic Failover & Election Process

  

```mermaid

stateDiagram-v2

Â  Â  [*] --> NormalOperation: Replica Set Initialized

Â  Â  state NormalOperation {

Â  Â  Â  Â  P[Primary Node
2717] --> S1[Secondary Node 1
2727]: Heartbeats

Â  Â  Â  Â  P --> S2[Secondary Node 2
2737]: Heartbeats

Â  Â  Â  Â  S1 --> S2: Heartbeats

Â  Â  }

Â  Â  NormalOperation --> PrimaryFailure: Primary Unreachable

Â  Â  state PrimaryFailure {

Â  Â  Â  Â  F[Primary Failed
No Heartbeat Response]

Â  Â  Â  Â  S1 --> S2: Election Initiation

Â  Â  Â  Â  S2 --> S1: Vote Exchange

Â  Â  }

Â  Â  PrimaryFailure --> ElectionInProgress: Majority Detects Failure

Â  Â  state ElectionInProgress {

Â  Â  Â  Â  S1 --> S1: Campaign for Primary

Â  Â  Â  Â  S2 --> S2: Campaign for Primary

Â  Â  Â  Â  S1 --> S2: Request Votes

Â  Â  Â  Â  S2 --> S1: Grant Votes

Â  Â  }

Â  Â  ElectionInProgress --> NewPrimary: Majority Elects New Primary

Â  Â  state NewPrimary {

Â  Â  Â  Â  NP[New Primary
2727 Elected] --> S2[Secondary
2737]: Replication Resumes

Â  Â  Â  Â  NP --> OF[Old Primary
2717]: Marked as Secondary
(When Recovered)

Â  Â  }

Â  Â  NewPrimary --> [*]: Stable State Achieved

```

  

### ğŸ› ï¸ Technical Explanation â€“ Automatic Failover
---
MongoDB implements **automatic failover** through the **Raft consensus algorithm**, ensuring high availability:

1. **ğŸ’“ Heartbeat Monitoring**  
   - All nodes exchange **heartbeats every 2 seconds** to monitor cluster health  
---
2. **âš ï¸ Failure Detection**  
   - If **Secondaries** don't receive a heartbeat from the **Primary** within **10 seconds**, they initiate an **election**  
---
3. **ğŸ Election Process**  
   - **Eligible Secondaries** (priority > 0, not hidden, up-to-date oplog) campaign to become **Primary**  
   - Nodes **vote** based on election criteria:  
     - Priority  
     - Data freshness  
     - Network connectivity  
   - Candidate requires **majority vote** (`n/2 + 1`) to be elected  
---
4. **ğŸŒŸ New Primary**  
   - The **elected node transitions to Primary**  
   - Resumes **replication** to remaining Secondaries  
---
5. **ğŸ”„ Old Primary Recovery**  
   - When a **failed node recovers**, it rejoins as a **Secondary**  
   - Syncs **missing data** to catch up with the current Primary  

> âš¡ Automatic failover ensures **high availability**, **data consistency**, and **minimal downtime** in a MongoDB Replica Set.


  

## 4ï¸âƒ£ Data Replication Synchronization

  

```mermaid

flowchart TD

Â  Â  subgraph "Primary Node (2717)"

Â  Â  Â  Â  direction LR

Â  Â  Â  Â  P1[Application Data
Collections]

Â  Â  Â  Â  P2[Oplog
Capped Collection]

Â  Â  Â  Â  P1 -- "All Write Operations" --> P2

Â  Â  end

Â  Â  subgraph "Secondary Node 1 (2727)"

Â  Â  Â  Â  direction LR

Â  Â  Â  Â  S1_1[Sync Source
Primary's Oplog]

Â  Â  Â  Â  S1_2[Data Apply
Replay Operations]

Â  Â  Â  Â  S1_3[Local Data
Replicated Copy]

Â  Â  Â  Â  S1_1 --> S1_2 --> S1_3

Â  Â  end

Â  Â  subgraph "Secondary Node 2 (2737)"

Â  Â  Â  Â  direction LR

Â  Â  Â  Â  S2_1[Sync Source
Primary's Oplog]

Â  Â  Â  Â  S2_2[Data Apply
Replay Operations]

Â  Â  Â  Â  S2_3[Local Data
Replicated Copy]

Â  Â  Â  Â  S2_1 --> S2_2 --> S2_3

Â  Â  end

Â  Â  P2 -- "1. Oplog Entries Streamed
(tailable cursor)" --> S1_1

Â  Â  P2 -- "1. Oplog Entries Streamed
(tailable cursor)" --> S2_1

Â  Â  S1_2 -- "2. Apply in Original Order
(idempotent operations)" --> S1_3

Â  Â  S2_2 -- "2. Apply in Original Order
(idempotent operations)" --> S2_3

Â  Â  S1_1 -- "3. Heartbeat & Status Report" --> P2

Â  Â  S2_1 -- "3. Heartbeat & Status Report" --> P2

```

  

### ğŸ”„ Technical Explanation â€“ Data Replication in MongoDB

---
MongoDB uses a **pull-based replication model** via the **Oplog** to ensure data consistency across Replica Set nodes.
---

#### ğŸ—‚ï¸ Oplog Structure
- A **capped collection** storing **idempotent operations** (`insert`, `update`, `delete`) with **timestamps**  
- Serves as the source for replication to Secondaries  

---

#### ğŸ” Replication Process
1. **Secondaries** maintain a **tailable cursor** on the Primary's Oplog  
2. **New operations** are streamed to Secondaries **in real-time**  
3. Each Secondary applies operations **in the same order as the Primary**  

---

#### âš¡ Initial Sync
- New nodes perform:  
  - **Full data copy**  
  - **Oplog application** to catch up with Primary  

---

#### âœ… Consistency Guarantees
- Controlled by **write concern options**:  
  - `w: 1` â†’ Acknowledged by Primary  
  - `w: majority` â†’ Acknowledged by most nodes  
  - `w: all` â†’ Acknowledged by all nodes  

---

#### ğŸ“Š Lag Monitoring
- `rs.status()` / `replSetGetStatus` shows **replication lag**  
- Optimal production lag: **< 50ms**  

---

### ğŸ—ï¸ Production Best Practices (3-node Replica Set)
- **Write Concerns**: Use `w: "majority"` for critical data to ensure durability  
- **Read Preferences**:  
  - `primary` â†’ Strong consistency  
  - `secondaryPreferred` â†’ Read scaling  
- **Connection String**:  
```text
mongodb://localhost:2717,localhost:2727,localhost:2737/?replicaSet=myReplicaSet
